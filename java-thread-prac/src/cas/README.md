# 원자적 연산
- int i = 0; 은 원자적 연산이다
- i++;은 원자적 연산이 아니다
- i++;은 실제로 i값을 확인하고 i값에 새로운 값을 넣는 두 가지 동작이기 때문이다.
- 그렇다면 멀티스레드 상황에서 아주 미세한 시점에서, A스레드가 i값을 확인하고, i값에 새로운 값을 넣기 직전 B스레드가 i값을 바꾼다면, A는 바뀌기 이전 값에 +1 값을 업데이트한다.
- 이건 임계영역 처리(synchronized or ReentrantLock)으로 해결가능하지 않나?
- 그렇다. AtomicInteger.increamentAndGet()를 사용하면 임계영역처럼 처리되어 안전하게 값을 확인 및 증가시킬 수 있다.
- 그렇다면 AtomicInteger는 synchronized나 ReentrantLock처럼 Lock을 통해 임계영역으로 처리해서 연산을 안전하게 수행하는건가?
- 그렇지 않다. AtomicInteger는 CAS 연산이라는 것을 사용하여 Lock을 통하지 않은(Lock Free) 임계영역 연산처리를 가능케 한다.
- CAS = CompareAndSet 이며 비교하고 셋팅한다라는 이름 그대로의 뜻이다.
- 데이터를 비교하고, 셋팅한다는 것은 두 단계의 일이다. 이를 임계영역 처리하지 않는다면 셋팅 시점에 데이터가 달라지지 않았다는 것을 보장할 수 없다.
- CAS는 CPU자체에서 지원하는 기능이다. CompareAndSet 두 과정을 하나의 `원자적 연산`으로 처리해준다.
- 즉 비교하고 세팅하는 그 과정에서 하드웨어 차원에서 다른 누군가의 접근을 막는 것이다.
- 실제 실험 결과 락 기법보다 빠르다.
- CAS를 통해 우리는 락이 없이 increamentAndGet과 같은 기능이나 심지어는 우리가 아는 락(모니터락, ReentrantLock)이없는 락기능도 만들 수 있다.
- CAS를 통해 lock(), unlock()을 만들기 위해서는 락을 얻지 않고 최종 데이터가 업데이트 되는 시점에 데이터를 확인하고 데이터가 변했다면 다시 로직을 수행하는 재시도 기법을 도입한다.
- 기존 ReentrantLock이나 synchronized의 경우 데이터 충돌을 피하기 위해 충돌이 날 영역 자체를 "한 스레드"만 접근하도록 하였다.
- 접근할 때 락을 얻어야하고 다쓰고나면 반납도 해야한다. <- 이것은 비용이며 이 과정에서 RUNNABLE이 WAITING이 되거나 BLOCKED 되는 등 스레드 상태가 변화하고 OS 스케줄링에서도 빠지거나 들어가는 등 스위칭이 이루어진다.
- CAS Lock은 그러한 단점(얻고, 반납하는)을 극복한다.
- 그럼 CAS Lock이 제일 좋은 것 아닐까? -> 기존에 배운 락 기능보다 상위의 기능아닌가?
- 아니다. 각각의 사용처가 존재한다.
- CAS Lock은 Lock을 얻지 못한다면 반복해서 얻기 위해 재시도한다. 이것이 CAS의 단점(비용)이다.
- 그렇기에 CAS Lock은 재시도 과정이 많아지면 (lockFlag 데이터 충돌로 인한 재시도 or lock을 기다리는 중일 때) CAS의 단점이 부각된다.
- CAS는 방안에 사람이 있는지 확인하기 위해 방문을 열고 확인하는 것이며, 이전에 배운 락은 아예 자물쇠로 잠가서 다른 사용자가 들어오기도 전에 포기하고 기다리는 상황이다.
- 대신 이전에 배운 락은 방을 사용하는 사람이 문을 잠가야하는 추가 행동과 문을 열때 열쇄를 반납해야하는 추가 행동이 필요하다.
- 만약 이 방이 매우 사용률이 적다면(동시 이용에 대해 충돌날 가능성이 적다면) 굳이 문을 잠구는 등의 철저한 침입금지 규칙은 오버코스트다.
- 이 방이 매우 사용률이 높다면(오래 사용한다던가, 많이들 사용한다던가) 지속적으로 방문을 열어두는 것 보다 잠궈서 미리 포기하게 만드는 것이 적절할 것이다.
- 그렇기에 짧은 연산에서는 비교시점과 설정시점의 데이터가 변질되는 경우가 적기에(충돌율 현저히 적음) 낙관적 기법인 CAS Lock과 같은 접근이 옳으며
- 긴 연산에서는 데이터가 변질될 경우가 많기에 기존에 배운 락으로 영역 자체를 잠궈버리는 것이 오히려 효율적인 것이다.

낙관적 락(CAS 활용 - 재시도를 통한 진입 시도)
비관적 락(synchronized or ReentrantLock 활용 - 열쇄를 확실하게 얻어 진입 시도)

# Optimistic vs Pessimistic Lock Performance Test

## 개요
본 테스트는 Java에서 비관적 락(`ReentrantLock`)과 낙관적 락(`CasLock`)의 성능 차이를 비교하기 위해 설계되었다.  
락 충돌이 적을 때 낙관적 락이 더 빠르다는 가설을 검증하기 위해 진행하였다.

---

## 테스트 환경 및 조건

- 락 종류:
    - 비관적 락: `java.util.concurrent.locks.ReentrantLock`
    - 낙관적 락: 커스텀 구현한 `CasLock` (AtomicBoolean 기반 스핀락)
- 스레드 수: 100개 (`ThreadCount = 100`)
- 각 스레드에서 수행하는 작업 횟수: 9,999,999번 (`dummyCount = 9999999`)
- 공유 변수: `dummy` (int, 단순 증가 연산)
- 측정 기준: 락이 걸린 상태에서 모든 스레드가 작업을 완료하는 데 걸린 시간 (밀리초)

---

## CasLock 구현 방식

낙관적 락인 `CasLock`은 AtomicBoolean의 `compareAndSet`을 이용하여 락을 획득하며,  
락 획득에 실패하면 `Thread.yield()`를 호출해 CPU 자원을 잠시 양보하는 스핀락 구조이다.

---

## 테스트 결과

| ThreadCount | Pessimistic Lock 시간 (ms) | Optimistic Lock 시간 (ms) | 비고                  |
|-------------|----------------------------|---------------------------|-----------------------|
| 100         | 58                         | 53                        | 거의 비슷한 성능       |
| 10,000      | 683                        | 349                       | 낙관적 락이 더 빠름   |

---

## 분석 및 결론

- 스레드 수가 적을 때(100개) 비관적 락과 낙관적 락 성능 차이가 크지 않다.
- 스레드 수가 많아질수록(10,000개) 낙관적 락이 비관적 락 대비 성능 우위를 보인다.
- 이는 많은 스레드가 락을 경쟁할 때, 비관적 락은 컨텍스트 스위칭으로 인한 오버헤드가 커지는 반면,  
  낙관적 락은 busy-waiting을 통해 락 획득을 빠르게 재시도할 수 있기 때문으로 판단된다.
- 다만, 낙관적 락의 busy-waiting은 CPU 자원을 많이 사용하므로 스레드 수와 CPU 코어 수, 임계 영역 길이에 따라 효율이 달라진다.

---

## 주요 인사이트

- 락 전략 선택은 스레드 수 및 임계 영역 특성에 따라 달라진다.
- 스레드 수가 많고 임계 영역이 짧은 경우 낙관적 락이 상대적으로 유리하다.
- 스레드 수가 적거나 임계 영역이 긴 경우 비관적 락이 더 안정적일 수 있다.

---
